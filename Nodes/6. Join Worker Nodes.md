Copy the join command you noted down in the previous topic.

Execute it on all the worker nodes using sudo.

For example,
```yaml
sudo kubeadm join 192.168.201.10:6443 --token cyvaxk.zuc4v8s1cya8valz --discovery-token-ca-cert-hash sha256:857cda3cbcb5b6f3c91c5a059eba78242183281bafa220d19306167a08376450
```

If you don't have the join command, execute the following command on the control plane node to get the join command.
```bash
kubeadm token create --print-join-command
```

Once the nodes are added successfully, if you **execute the following kubectl command from the control plane**, you should be able to list the nodes in a ready status, as shown below.
```bash
kubectl get nodes

NAME           STATUS      ROLES           AGE   VERSION<>
controlplane   NotReady    control-plane   26m   v1.30.0
node01         NotReady    <none>          37s   v1.30.0
node02         NotReady    <none>          19s   v1.30.0
node03         NotReady    <none>          3s    v1.30.0
```
You can see the nodes are in the **NotReady** state because a Network Plugin (CNI) is not yet installed in the cluster.

Kubernetes requires the CNI for pod networking, and without it, the nodes cannot communicate properly, that's why the nodes are in a **NotReady** state.

The node's status will be changed to **Ready** state once we install a Network Plugin in the cluster, which we will do in the next section.
